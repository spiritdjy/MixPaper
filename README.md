
<!-- TOC -->autoauto- [深度学习](#深度学习)auto    - [[理论、正则化](notes/DeepLearning.md)](#理论正则化notesdeeplearningmd)auto    - [[少样本学习](notes/ZeroShotLearning.md)](#少样本学习noteszeroshotlearningmd)auto    - [[压缩、剪枝、蒸馏、AUTOML](notes/Automl.md)](#压缩剪枝蒸馏automlnotesautomlmd)auto- [自然语言处理](#自然语言处理)auto    - [[语言模型](notes/LanguageModel.md)](#语言模型noteslanguagemodelmd)auto    - [[文本分类](notes/Classification.md)](#文本分类notesclassificationmd)auto    - [[语法分析:分词、实体识别、依存分析、指代消解等](notes/NlpGrammaticalAnalysis.md)](#语法分析分词实体识别依存分析指代消解等notesnlpgrammaticalanalysismd)auto    - [[表示学习：词向量、句向量](notes/Representation.md)](#表示学习词向量句向量notesrepresentationmd)auto    - [[文本匹配](notes/Match.md)](#文本匹配notesmatchmd)auto    - [[数据增强](notes/DataAugmentation.md)](#数据增强notesdataaugmentationmd)auto    - [[迁移学习](notes/TransferLearning.md)](#迁移学习notestransferlearningmd)auto    - [[关键词抽取](notes/KeyPhrase.md)](#关键词抽取noteskeyphrasemd)auto    - [[文本摘要](notes/Summarization.md)](#文本摘要notessummarizationmd)auto    - [[聊天机器人](notes/ChatBot.md)](#聊天机器人noteschatbotmd)auto    - [[假新闻检测](notes/FakeNewsDetection.md)](#假新闻检测notesfakenewsdetectionmd)auto    - [[知识图谱](notes/KnowlegeGraph.md)](#知识图谱notesknowlegegraphmd)auto    - [[机器翻译](notes/MachineTranslation.md)](#机器翻译notesmachinetranslationmd)auto    - [[自然语言生成](notes/NaturalLanguageGeneration.md)](#自然语言生成notesnaturallanguagegenerationmd)auto    - [[自然语言推理](notes/NaturalLanguageInference.md)](#自然语言推理notesnaturallanguageinferencemd)auto    - [[预训练语言模型](notes/PretrainedLangugeModel.md)](#预训练语言模型notespretrainedlangugemodelmd)auto    - [[阅读理解](notes/ReadingComprehension.md)](#阅读理解notesreadingcomprehensionmd)auto- [[推荐](notes/Recommendation.md)](#推荐notesrecommendationmd)auto- [工程](#工程)autoauto<!-- /TOC -->
# 深度学习
## [理论、正则化](notes/DeepLearning.md)
- [列表汇总](notes/DeepLearning.md)

---
**<font color=#e84118>激活函数</font>**
- [1606.08415 Gaussian Error Linear Units (GELUs) 高斯误差线性单位(GELUs)](resources/notes/d0001/dl_gelu.md)

---
**<font color=#e84118>正则化</font>**

---
**<font color=#e84118>损失函数</font>**

- [ ] [1911.02855 Dice Loss for Data-imbalanced NLP Tasks]
- [201801 AMSoftmax: Additive Margin Softmax for Face Verification](resources/notes/d0001/loss_201801_AMSoftmax.md)

- [201708 Focal Loss for Dense Object Detection](resources/notes/d0001/loss_201708_Focal_Loss.md)

## [少样本学习](notes/ZeroShotLearning.md)
- [列表汇总](notes/ZeroShotLearning.md)

## [压缩、剪枝、蒸馏、AUTOML](notes/Automl.md)
- [列表汇总](notes/Automl.md)

- [2002.12620 TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural Language Processing](resources/notes/d0001/auto_202002_tb.md)

# 自然语言处理
- [202003 Natural Language Processing Advancements By Deep Learning: A Survey](resources/notes/d0001/nlp_202003_dl_a_survey.md)
    - https://arxiv.org/abs/2003.01200

## [语言模型](notes/LanguageModel.md)
- [列表汇总](notes/LanguageModel.md)

-  [201911 Generalization through Memorization: Nearest Neighbor Language Models](resources/notes/d0001/lm_201911_knn_lm.md)

## [文本分类](notes/Classification.md)
- [列表汇总](notes/Classification.md)

----
- [2103.12407 Detecting Hate Speech with GPT-3 用 GPT-3检测仇恨言论](resources/notes/d0001/Classification_2103.12407.md)

----
- [202004 Deep Learning Based Text Classification: A Comprehensive Review](resources/notes/d0001/Classification_202004_Deep_Learning_Based_Text_Classification.md)
- [2014 Convolutional Neural Networks for Sentence Classification](resources/notes/d0001/Classification_2014_TextCNN__Convolutional_Neural_Networks_for_Sentence_Classification.md)
- [201412 Effective Use of Word Order for Text Categorization with Convolutional Neural Networks](resources/notes/d0001/classification_201412_Effective_Use_of_Word_Order_for_Text_Categorization_with_Convolutional_Neural_Networks.md)
- [2016 Hierarchical Attention Networks for Document Classification](resources/notes/d0001/classification_2016_hierarchical_attention_networks_for_document_classification.md)
- [2016 Recurrent Neural Network for Text Classification with Multi-Task Learning](resources/notes/d0001/classification_2016_Recurrent_Neural_Network_for_Text_Classification_with_MultiTask_Learning.md)
- [201607 Bag of Tricks for Efficient Text Classification](resources/notes/d0001/classification_201607_bag_of_tricks_for_efficient_text_classification.md)
- [2017ACL Deep Pyramid Convolutional Neural Networks for Text Categorization](resources/notes/d0001/classification_2017_Deep_Pyramid_Convolutional_Neural_Networks_for_Text_Categorization.md)
- [2018 Large-Scale Hierarchical Text Classification with Recursively Regularized Deep Graph-CNN](resources/notes/d0001/classification_2018_Large_Scale_Hierarchical_Text_Classification_with_Recursively_Regularized_Deep_Graph_CNN.md)

## [语法分析:分词、实体识别、依存分析、指代消解等](notes/NlpGrammaticalAnalysis.md)
- [列表汇总](notes/NlpGrammaticalAnalysis.md)

---
**<font color=#e84118>序列标注</font>**

- [201908 - LAN - Hierarchically-Refined Label Attention Network for Sequence Labeling](resources/notes/d0001/structlabel_201908_Hierarchically_Refined_Label_Attention_Network_for_Sequence_Labeling.md)

---
**<font color=#e84118>分词</font>**

- [201704 Character-based Joint Segmentation and POS Tagging for Chinese
using Bidirectional RNN-CRF](resources/notes/d0001/nlplac_201704_Character_based_Joint_Segmentation_and_POS_Tagging.md)
- [2019ACL Is Word Segmentation Necessary for Deep Learning of Chinese Representations?](resources/notes/d0001/nlplac_2019_is_word_segmentation_necessary_for_deep_learning_of_chinese_representations.md)

----
**<font color=#e84118>命名实体识别</font>**

- [2101.00396 Lex-BERT: Enhancing BERT based NER with lexicons Lex-BERT: 用词典增强基于 BERT 的 NER](resources/notes/d0001/ner_2101.00396.md)
- [ ] [2101.11420 Recent Trends in Named Entity Recognition (NER) 命名实体识别(NER)的最新发展趋势](resources/notes/d0001/ner_2101.11420.md)
- [202002 Rethinking Generalization of Neural Models: A Named Entity Recognition Case Study](resources/notes/d0001/ner_202002_Rethinking_Generalization_of_Neural_Models.md)
- [202002 Zero-Resource Cross-Domain Named Entity Recognition](resources/notes/d0001/ner_202002_Zero_Resource_Cross_Domain_Named_Entity_Recognition.md)
- [201812 A Survey on Deep Learning for Named Entity Recognition](resources/notes/d0001/ner_201812_A_Survey_Named_Entity_Recognition.md)

---
**<font color=#e84118>指代消解</font>**


---
**<font color=#e84118>语义角色</font>**


---
**<font color=#e84118>依存分析</font>**


---
**<font color=#e84118>NLU</font>**
- [2012.15639 TexSmart: A Text Understanding System for Fine-Grained NER and Enhanced Semantic Analysis 一个用于细粒度 NER 和增强语义分析的文本理解系统](resources/notes/d0001/ner_201812_2012.15639.md)


## [表示学习：词向量、句向量](notes/Representation.md)
- [列表汇总](notes/Representation.md)

---
**<font color=#e84118>词向量</font>**

- [2014 Glove: Global Vectors for Word Representation](resources/notes/d0001/w2v_2014_Glove__Global_Vectors_for_Word_Representation.md)
- [2013 Efficient Estimation of Word Representations in Vector Space](resources/notes/d0001/w2v_2013_efficient_estimation_of_word_representations_in_vector_space.md)
- [2013 Distributed Representations of Words and Phrases and their Compositionality](resources/notes/d0001/w2v_2013_distributed_representations_of_words_and_phrases_and_their_compositionality.md)

---
**<font color=#e84118>句向量</font>**
- [2015 From Word Embeddings To Document Distances](resources/notes/d0001/d2v_2015_From_Word_Embeddings_To_Document_Distances.md)
- [2014 Doc2Vec Distributed Representations of Sentences and Documents](resources/notes/d0001/d2v_2014_distributed_representations_of_sentences_and_documents.md)

## [文本匹配](notes/Match.md)
- [列表汇总](notes/Match.md)

- [201908 Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks](resources/notes/d0001/pretrain_2019_sentence_bert.md)
- [2019 Keyword-Attentive Deep Semantic Matching](resources/notes/d0001/pretrain_2019_keyword_attentive_deep_semantic_matching.md)
- [201908 ACL RE2: Simple and Effective Text Matching with Richer Alignment Features](resources/notes/d0001/match201908_ACL_RE2__Simple_and_Effective_Text_Matching_with_Richer_Alignment_Features.md)
- [201905 FAQ Retrieval using Query-Question Similarity and BERT-Based Query-Answer Relevance](resources/notes/d0001/match_201905_ACL_FAQ_Retrieval_using_Query_Question_Similarity_and_BERT_Based_Query_Answer_Relevance.md)
- [201904 Understanding the Behaviors of BERT in Ranking](resources/notes/d0001/match_201904_Understanding_the_Behaviors_of_BERT_in_Ranking.md)
- [201804 SAN - Stochastic Answer Networks for Natural Language Inference](resources/notes/d0001/match_201804_Stochastic_Answer_Networks_for_Natural_Language_Inference.md)
- [201609 ESIM Enhanced LSTM for Natural Language Inference](resources/notes/d0001/match_2016_Enhanced_LSTM_for_Natural_Language_Inference.md)
- [2013 DSSM Learning Deep Structured Semantic Models for Web Search using Clickthrough Data](resources/notes/d0001/match_2013_Learning_Deep_Structured_Semantic_Models_for_Web_Search_using_Clickthrough_Data.md)
- [201606 A Decomposable Attention Model for Natural Language Inference](resources/notes/d0001/match_201606_A_Decomposable_Attention_Model_for_Natural_Language_Inference.md)

## [数据增强](notes/DataAugmentation.md)
- [列表汇总](notes/DataAugmentation.md)

- [202004 When does data augmentation help generalization in NLP?](resources/notes/d0001/DataAugNLP_202004_When_does_data_augmentation_help_generalization.md)
- [1904.12848 Unsupervised Data Augmentation 无监督数据增强](resources/notes/d0001/DataAugNLP_202004_1904.12848.md)
- [201901 EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification ](resources/notes/d0001/DataAugNLP_201901_EDA__Easy_Data_Augmentation_Techniques_for_Boosting_Performance_onText_Classification_Tasks.md)

## [迁移学习](notes/TransferLearning.md)
- [列表汇总](notes/TransferLearning.md)

- [202005 Cross-lingual Transfer of Twitter Sentiment Models Using a Common Vector Space](resources/notes/d0001/transnlp_202005_Cross_lingual_Transfer.md)

## [关键词抽取](notes/KeyPhrase.md)
- [列表汇总](notes/KeyPhrase.md)

---
**<font color=#e84118>Review</font>**
- [2009.10229 An Empirical Study on Neural Keyphrase Generation 神经关键词生成的实证研究](resources/notes/d0001/keyphrase_2009.10229.md)

- [201905 A review of keyphrase extraction](resources/notes/d0001/keyphrase_2019_A_Review_of_Keyphrase_Extraction.md)

---
**<font color=#e84118>Unsupervised</font>**
- [2004.13639 Joint Keyphrase Chunking and Salience Ranking with BERT 基于BERT联合关键词分组和显著性排序](resources/notes/d0001/keyphrase_2020_2004.13639.md)
- [202002 SIFRank: A New Baseline for Unsupervised Keyphrase Extraction Based on Pre-Trained Language Model 基于预训练语言模型的无监督关键词提取基线 SIFRank](resources/notes/d0001/keyphrase_2020_SIFrank.md)

- [2018 ACL EmbedRank++ Simple Unsupervised Keyphrase Extraction using Sentence Embeddings](resources/notes/d0001/keyphrase_2018_simple_unsupervisd_keyphrase_embedding.md)

---
**<font color=#e84118>Supervised</font>**


## [文本摘要](notes/Summarization.md)
- [列表汇总](notes/Summarization.md)

---
**<font color=#e84118>General</font>**

- [201907 Simple Unsupervised Summarization by Contextual Matching](resources/notes/d0001/summarization_201907_Unsupervised_Summarization_by_Contextual_Matching.md)

---
**<font color=#e84118>Extractive</font>**

- [201903 Fine-tune BERT for Extractive Summarization](resources/notes/d0001/summarization_2019_fine_tune_bert.md)
- [2019ACL Single Document Summarization as Tree Induction](resources/notes/d0001/summarization_2019ACL_Single_Document_Summarization_as_Tree_Induction.md)

---
**<font color=#e84118>Abstractive</font>**


## [聊天机器人](notes/ChatBot.md)
- [列表汇总](notes/ChatBot.md)

--- 
**<font color=#e84118>Task-oriented</font>**

- [202003 Recent Advances and Challenges in Task-oriented Dialog System](resources/notes/d0001/chatbot_202003_Recent_Advances_and_Challenges_in_Task_oriented_Dialog_System.md)

--- 
**<font color=#e84118>Dialogue</font>**

- [201911 DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation](resources/notes/d0001/chatbot_201911_DialoGPT__Large_Scale_Generative_Pre_training_for_Conversational_Response.md)

---
**<font color=#e84118>意图识别与槽抽取</font>**
- [列表](notes/Intent&Slot.md)

- [2103.15871 Industry Scale Semi-Supervised Learning for Natural Language Understanding 自然语言理解的工业规模半监督学习](resources/notes/d0001/intent_2103.15871.md)
- [201902 BERT for Joint Intent Classification and Slot Filling](resources/notes/d0001/intent_201902_BERT_for_Joint_Intent_Classification_and_Slot_Filling.md)

## [假新闻检测](notes/FakeNewsDetection.md)
- [列表汇总](notes/FakeNewsDetection.md)

## [知识图谱](notes/KnowlegeGraph.md)
- [列表汇总](notes/KnowlegeGraph.md)

---
**<font color=#e84118>Entity Linking</font>**

---
**<font color=#e84118>Relation Extraction</font>**
- [2102.01373 An Improved Baseline for Sentence-level Relation Extraction 一种改进的句级关系抽取基线](resources/notes/d0001/kgre_2102.01373.md)
- [ ] [2102.01156 Improving Distantly-Supervised Relation Extraction through BERT-based Label & Instance Embeddings 基于 bert 标记和实例嵌入的远监督关系抽取](resources/notes/d0001/kgre_2102.01156.md)

- [2010.12812 A Frustratingly Easy Approach for Entity and Relation Extraction 一种简单得令人沮丧的实体和关系抽取方法](resources/notes/d0001/kgre_2020_2010.12812.md)
- [202004 Review and Outlook for Relation Extraction](resources/notes/d0001/kgre_2020_Review_and_Outlook_for_Relation_Extraction.md)
- [1711.07010 A Discourse-Level Named Entity Recognition and Relation Extraction Dataset for Chinese Literature Text 中文文学作品命名实体识别与关系抽取数据集](resources/notes/d0001/kgre_1711.07010.md)

---
**<font color=#e84118>Event Extraction</font>**


## [机器翻译](notes/MachineTranslation.md)
- [列表汇总](notes/MachineTranslation.md)

- [201409 Neural Machine Translation by Jointly Learning to Align and Translate](resources/notes/d0001/mt_201409_Neural_Machine_Translation_by_Jointly_Learning_to_Align_and_Translate.md)
- [201409 Sequence to Sequence Learning with Neural Networks](resources/notes/d0001/seq2seq_201409_Sequence_to_Sequence_Learning_with_Neural_Networks.md)

## [自然语言生成](notes/NaturalLanguageGeneration.md)
- [列表汇总](notes/MachineTranslation.md)

---
**<font color=#e84118>Chatbot</font>**

- [202004 Few-Shot Natural Language Generation by Rewriting Templates](resources/notes/d0001/NLG_202004_Few_Shot_Natural_Language_Generation_by_Rewriting_Templates.md)

---
**<font color=#e84118>诗歌</font>**

- [2019 基于神经网络的集句诗自动生成](resources/notes/d0001/NLG_Poetry_2019_Neural_Network_based_Jiju_Poetry_Generation.md)

---
**<font color=#e84118>新闻评论</font>**

- [201909 Read, Attend and Comment: A Deep Architecture for Automatic News Comment Generation](resources/notes/d0001/comment_201910_Read__Attend_and_Comment__A_Deep_Architecture_for_Automatic_News_Comment_Generation.md)
- [201906 Coherent Comment Generation for Chinese Articles with a Graph-to-Sequence Model](resources/notes/d0001/comment_201906_Coherent_Comment_Generation_for_Chinese_Articles_with_a_Graph_to_Sequence_Model.md)
- [201809 Unsupervised Machine Commenting with Neural Variational Topic Model](resources/notes/d0001/comment_201809_Unsupervised_Machine_Commenting_with_Neural_Variational_Topic_Model.md)
- [201805 Automatic Article Commenting: the Task and Dataset](resources/notes/d0001/comment_201805_Automatic_Article_Commenting__the_Task_and_Dataset.md)

---
**<font color=#e84118>评论评价</font>**

---
**<font color=#e84118>Pretrain ML</font>**

- [201909 A Conditional Transformer Language Model for Controllable Generation](resources/notes/d0001/nlg_201909_A_Conditional_Transformer_Language_Model_for_Controllable_Generation.md)

## [自然语言推理](notes/NaturalLanguageInference.md)
- [列表汇总](notes/NaturalLanguageInference.md)

## [预训练语言模型](notes/PretrainedLangugeModel.md)
- [列表汇总](notes/PretrainedLangugeModel.md)

- [2103.06874 CANINE: Pre-training an Efficient Tokenization-Free Encoder
for Language Representation](resources/notes/d0001/pretrainlm_2103.06874.md)
- [2103.04350 Syntax-BERT: Improving Pre-trained Transformers with Syntax Trees](resources/FastReading.md#2103.04350Syntax-BERT:ImprovingPre-trainedTransformerswithSyntaxTrees)
---
**<font color=#e84118>模型</font>**
- [2103.10360 All NLP Tasks Are Generation Tasks: A General Pretraining Framework 所有 NLP 任务都是生成任务: 一个通用的预训练框架](resources/notes/d0001/pretrainlm_2103.10360.md)
- [2103.04350 Syntax-BERT: Improving Pre-trained Transformers with Syntax Trees](notes/FastReading.md#2103.04350Syntax-BERT:ImprovingPre-trainedTransformerswithSyntaxTrees)
- [2103.06874 CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation](resources/notes/d0001/pretrainlm_2103.06874.md)

- [202004 DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference](resources/notes/d0001/pretrainlm_202004_DeeBert.md)
- [202004 Don’t Stop Pretraining: Adapt Language Models to Domains and Tasks](resources/notes/d0001/pretrainlm_202004_Adapt_Language_Models_to_Domains_and_Tasks.md)
- [202003 Pre-trained Models for Natural Language Processing: A Survey](resources/notes/d0001/pretrainlm_202003_Survey.md)
- [2020 ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators](resources/notes/d0001/pretrainlm_2020_ELECTRA__Pre-training_Text_Encoders_as_Discriminators_Rather_Than_Generators.md)
- [202001 ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training](resources/notes/d0001/pretrain_202001_ProphetNet_Predicting_Future_N_gram_for_Sequence_to_Sequence_Pre_training.md)
- [201909 ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](resources/notes/d0001/pretrainlm_201909_ALBERT__A_Lite_BERT_for_Self_supervised_Learning_of_Language_Representations.md)
- [201909 NEZHA: NEURAL CONTEXTUALIZED REPRESENTATION FOR CHINESE LANGUAGE UNDERSTANDING](resources/notes/d0001/pretrainlm_201909_nezha__neural_contextualized_representation_for_chinese_language_understanding.md)
- [201907 ERNIE 2.0: A Continual Pre-Training Framework for Language Understanding](resources/notes/d0001/pretrainml_201907_ERNIE_2.0__A_Continual_Pre_Training_Framework_for_Language_Understanding.md)
- [201906 RoBERTa: A Robustly Optimized BERT Pretraining Approach](resources/notes/d0001/pretrainlm_201907_RoBERTa__A_Robustly_Optimized_BERT_Pretraining_Approach.md)
- [201906 ERNIE: Enhanced Language Representation with Informative Entities（THU/ACL2019）](resources/notes/d0001/pretrainml_201907_ERNIE__Enhanced_Language_Representation_with_Informative_Entities.md)
- [1905.03197 Unified Language Model Pre-training for Natural Language Understanding and Generation](resources/notes/d0001/pretrainml_201905_unlm.md)
- [201904 ERNIE: Enhanced Representation through Knowledge Integration](resources/notes/d0001/pretrainml_201904_ERNIE__Enhanced_Representation_through_Knowledge_Integration.md)
- [2018 ACL Deep contextualized word representations: ELMO](resources/notes/d0001/pretrainlm_2018_deep_contextualized_word_representations.md)
- [2018 GPT Improving Language Understanding by Generative Pre-Training](resources/notes/d0001/pretrainlm_2018_gpt_Improving_Language_Understanding_by_Generative_Pre_Training.md)
- [201801 Universal Language Model Fine-tuning for Text Classification](resources/notes/d0001/pretrainlm_201801_Universal_Language_Model_Fine_tuning_for_Text_Classification.md)
- [201706 attention is all you need](resources/notes/d0001/attention_2017_attention_is_all_you_need.md)

---
**<font color=#e84118>蒸馏</font>**

- [1909.10351 TinyBERT: Distilling BERT for Natural Language Understanding](resources/notes/d0001/pretrainlm_1909_tinyBERT.md)
- [1910.01108 DistilBERT,adistilledversionofBERT:smaller, faster,cheaperandlighter](resources/notes/d0001/pretrainlm_1910_DistilBERT.md)
- [1908.08962 Well-Read Students Learn Better: On the Importance of Pre-training Compact Models](resources/notes/d0001/pretrainlm_1908_pdbert.md)

---
**<font color=#e84118>应用</font>**
- [2101.10642 Evaluation of BERT and ALBERT Sentence Embedding Performance on Downstream NLP Tasks BERT 和 ALBERT 句子嵌入对下游自然语言处理任务的影响](resources/notes/d0001/pretrainlm_2101.10642.md)
- [2010.05522 Pre-trained Language Model Based Active Learning for Sentence Matching 基于预训练语言模型的主动学习句子匹配](resources/notes/d0001/pretrainlm_2010.05522.md)
- [2103.10385 GPT Understands, Too GPT 也能理解](resources/notes/d0001/pretrainlm_2103.10385.md)
- [2103.10673 Cost-effective Deployment of BERT Models in Serverless Environment 无服务环境下 BERT 模型的性价比部署](resources/notes/d0001/pretrainlm_2103.10673.md)
- [2004.02288 Continual Domain-Tuning for Pretrained Language Models  预训练语言模型的持续域微调](resources/notes/d0001/pretrainlm_2004.02288.md)
- [202004 Pre-training Is (Almost) All You Need: An Application to Commonsense Reasoning](resources/notes/d0001/pretrainlm_202004_Pre_training_Is_Almost_All_You_Need.md)
- [202002 REALM: Retrieval-Augmented Language Model Pre-Training](resources/notes/d0001/pretrainlm_202002_REALM.md)

---
**<font color=#e84118>情感分类</font>**

- [2103.07098 A Weakly Supervised Approach for Classifying Stance in Twitter Replies](resources/notes/d0001/pretrainlm_2103.07098.md)

- [202005 SKEP: Sentiment Knowledge Enhanced Pre-training for Sentiment Analysis](resources/notes/d0001/pretrainlm_202005_SKEP_Sentiment_Knowledge.md)

---
**<font color=#e84118>原理</font>**

- [202003 What the MASK? Making Sense of Language-Specific BERT Models](resources/notes/d0001/pretrainlm_202003_What_the_MASK_.md)
- [202002 A Primer in BERTology: What we know about how BERT works](resources/notes/d0001/pretrain_202002_A_Primer_in_BERTology.md)
- [201909 How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings](resources/notes/d0001/pretrain_201909_How_Contextual_are_Contextualized_Word_Representations.md)
- [201910 T5 Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](resources/notes/d0001/pretrainlm_201910_T5_Exploring_the_Limits_of_Transfer_Learning_with_a_Unified_Text_to_Text_Transformer.md)

## [阅读理解](notes/ReadingComprehension.md)
- [列表汇总](notes/ReadingComprehension.md)

---
**<font color=#e84118>综述</font>**

---
**<font color=#e84118>开放领域</font>**

---
**<font color=#e84118>KBQA</font>**
- [2104.00218 Integrating Subgraph-aware Relation and Direction Reasoning for Question Answering 基于子图感知关系和方向推理的问答系统](resources/notes/d0001/qa_2104.00218.md)


# [推荐](notes/Recommendation.md)
- [列表汇总](notes/Recommendation.md)

---
**<font color=#e84118>概念挖掘</font>**

---
**<font color=#e84118>模型</font>**

- [ ] [202011 Graph Neural Networks in Recommender Systems: A Survey](resources/notes/d0001/rec_202011_GNN_Survey.md)

- [1703.04247 DeepFM: A Factorization-Machine based Neural Network for CTR Prediction](resources/notes/d0001/rec_deepFM.md)

- [201606  Wide & Deep Learning for Recommender Systems](resources/notes/d0001/rec_201606_Wide__Deep_Learning_for_Recommender_Systems.md)
- [1601.02376 Deep Learning over Multi-field Categorical Data: A Case Study on User Response Prediction](resources/notes/d0001/rec_1601_FNN.md)

- [2010 Factorization Machines](resources/notes/d0001/rec_2010_Factorization_Machines.md)

---
**<font color=#e84118>新闻推荐</font>**

- [1801.08284 DKN: Deep Knowledge-Aware Network for News Recommendation](resources/notes/d0001/rec_DKN_news.md)

- [KDD2017 Embedding-based News Recommendation for Millions of Users](resources/notes/d0001/rec_kdd2017_news.md)


# 工程


